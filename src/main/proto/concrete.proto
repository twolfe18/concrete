/* 
 * Copyright 2012-2013 Johns Hopkins University HLTCOE. All rights reserved.
 * This software is released under the 2-clause BSD license.
 * See LICENSE in the project root directory.
 */

/**
 * Concrete - Rebar ProtoBuf serialization definitions
 * 
 */

option java_package="edu.jhu.concrete";
package concrete;

//===========================================================================
// Conventions
//===========================================================================

/**______________________________________________________________________
  * TIMES
  *     Times and dates are encoded as unix time UTC (i.e., seconds
  *     since January 1, 1970), stored in a double field.
  *______________________________________________________________________
  * LANGUAGES
  *     Languages are encoded using ISO 639-3 three-letter codes.
  *     Other language code formats, such as ISO 639-1 two-letter
  *     codes (<http://en.wikipedia.org/wiki/ISO_639-1>) and
  *     Ethnologue SIL codes (<http://www.ethnologue.com/codes/>)
  *     should be mapped to the corresponding ISO 639-3 code.
  * 
  *     Two special codes should be noted:
  *     <ul>
  *       <li> und: Language is undetermined </li>
  *       <li> zxx: No linguistic content </li>
  *     </ul>
  *______________________________________________________________________
  */ 

//===========================================================================
// Universally Unique Identifiers
//===========================================================================

/** A 16-byte UUID identifier.
  *
  * @see http://en.wikipedia.org/wiki/Universally_unique_identifier 
  */
message UUID {
  optional fixed64 high = 1; //!< The 8 most significant bytes
  optional fixed64 low = 2;  //!< The 8 least significant bytes
}


//===========================================================================
// Communications
//===========================================================================

/** A globally unique identifier for a communication object that comes
 * from a persistent corpus.  This identifier is meant to be stable,
 * and directly mappable back to the source document(s) in the
 * persistent corpus (unlike UUIDs, which are randomly generated). */
message CommunicationGUID {
  /** The name of the corpus.  Each corpus should be assigned
   * a globally unique name; ensuring this global uniqueness is 
   * the responsibility of the user. */
  optional string corpus_name = 1;

  /** A string identifier that uniquely identifies a single
   * communication within the corpus.  Typically this will be a file
   * or document identifier from the corpus.  In cases where a single
   * communication contains multiple files/documents, this identifier
   * may have a different form.
   *
   * This identifier is typically used to index the Communication
   * objects within a corpus -- i.e., if you wish to load a
   * Communication, then you need to know its communication_id. */
  optional string communication_id = 2; 
}

/** A single communication instance, containing linguistic content
  * generated by a single speaker or author.  This type is used for
  * both inter-personal communications (such as phone calls or
  * conversations) and third-party communications (such as news
  * articles).
  *
  * Each communication instance is grounded by its original
  * (unannotated) contents, which should be stored in either the
  * "text" field (for text communications) or the "audio" field (for
  * audio communications).  If the communication is not available in
  * its original form, then these fields should store the
  * communication in the least-processed form available.
  */
message Communication {
  /*========================== Identifiers ==========================*/

  /** Stable identifier for this communication, identifying both the
   * name of the source corpus and the document that it corresponds to
   * in that corpus. */
  required CommunicationGUID guid = 1;

  /** Universally unique identifier for this communication instance.
   * This is generated randomly, and can *not* be mapped back to the
   * source corpus.  It is used as a target for symbolic "pointers". */
  required UUID uuid = 2;

  /*=================== "Raw Input" Fields ====================== */

  /** The full text contents of this communication in its original
   * form, or in the least-processed form available, if the original
   * is not available. */
  optional string text = 3;

  /** The full audio contents of this communication in its original
   * form, or in the least-processed form available, if the original
   * is not available. */
  optional Sound audio = 4;
  
  /** The time when this communication started (in unix time UTC --
   * i.e., seconds since January 1, 1970).  */
  optional double start_time = 5;

  /** The time when this communication ended (in unix time UTC --
   * i.e., seconds since January 1, 1970). */
  optional double end_time = 6;

  /*=================== Annotation Fields ====================== */

  /** Theories about the block structure of this communication. */
  repeated SectionSegmentation section_segmentation = 8;

  /** Theories about the languages that are present in this
   * communication. */
  repeated LanguageIdentification language_id = 14;

  /** Theories about the gender of the speaker or author of this
   * communication. */
  // Mark this in the knowledge graph instead??
  //repeated GenderIdentification sender_gender_id = 16;

  /** Theories about which spans of text are used to mention entities
   * in this communication. */
  repeated EntityMentionSet entity_mention_set = 9;

  /** Theories about what entities are discussed in this
   * communication, with pointers to individual mentions. */
  repeated EntitySet entity_set = 10;

  /** Theories about what situations are explicitly mentioned in this
   * communication. */
  repeated SituationMentionSet situation_mention_set = 20;

  /** Theories about what situations are asserted in this
   * communication. */
  repeated SituationSet situation_set = 21;

  /** Theories about what concepts are mentioned or discussed in this
   * communication. */
  repeated ConceptSet related_concept_set = 17;

  /** Raw SERIF output for this communication. */
  repeated SerifXML serifxml = 18;

  /*=================== Kind-Specific Fields ====================== */

  /** An enumeration used to indicate what type of communication this
    * is.  The optional fields named "<i>kind</i>_info" can be used to
    * store extra fields that are specific to the communication
    * type. */
  optional Kind kind = 15 [default=OTHER];
  enum Kind {
    OTHER = 0;
    EMAIL = 1;
    NEWS = 2;
    WIKIPEDIA = 3;
    TWEET = 4;
    PHONE_CALL = 5;
    // This list is intended to grow over time.
  };

  /** Extra information for communications where kind==EMAIL */
  optional EmailCommunicationInfo email_info = 1001;
  /** Extra information for communications where kind==PHONE_CALL */
  optional PhoneCallCommunicationInfo phone_call_info = 1002;

  /** Extra information for communications where kind==TWEET:
   * Information about this tweet that is provided by the Twitter
   * API.  For information about the Twitter API, see:
   * <https://dev.twitter.com/docs/platform-objects> */
  optional TweetInfo tweet_info = 1004;

  /*=================== Knowledge Graph ====================== */

  /** The knowledge graph for this communication. */
  required KnowledgeGraph knowledge_graph = 7;
}

/** A theory about what languages are present in a given communication
 * or piece of communication.  Note that it is possible to have more
 * than one language present in a given communication. */
message LanguageIdentification {
  /** Unique identifier for this language identification. */
  required UUID uuid = 1;
  
  /** Information about where this language identification came from. */
  optional AnnotationMetadata metadata = 2;

  /** A list mapping from a language to the probability that that
   * language occurs in a given communication.  Each language code should
   * occur at most once in this list.  The probabilities do <i>not</i>
   * need to sum to one -- for example, if a single communication is known
   * to contain both English and French, then it would be appropriate
   * to assign a probability of 1 to both langauges.  (Manually
   * annotated LanguageProb objects should always have probabilities
   * of either zero or one; machine-generated LanguageProbs may have
   * intermediate probabilities.) */
  repeated LanguageProb language = 3;

  /** A message mapping a language to a probability */
  message LanguageProb {
    optional string language = 1;   //!< ISO 639-3 three-letter code
    optional float probability = 2;
  }
}

/** Extra information about an email communication instance. */
message EmailCommunicationInfo {
  // Information extracted from headers:
  optional string message_id = 1;
  optional string content_type = 2;
  optional string user_agent = 3;
  repeated string in_reply_to = 4; //!< defined by RFC 822, RFC 2822
  repeated string reference = 5; //!< defined by RFC 1036, RFC 2822
  optional EmailAddress senderAddress = 6;
  optional EmailAddress returnPathAddress = 7;
  repeated EmailAddress toAddress = 8;
  repeated EmailAddress ccAddress = 9;
  repeated EmailAddress bccAddress = 10;
}

/** An email address, optionally accompanied by a display_name.  These
  * values are typically extracted from strings such as: 
  * <tt> "John Smith" &lt;john\@xyz.com&gt; </tt>.
  * 
  * \see RFC2822 <http://tools.ietf.org/html/rfc2822>
  */
message EmailAddress {
  optional string address = 1;
  optional string display_name = 2;
}

/** Extra information about a phone-call communication instance. */
message PhoneCallCommunicationInfo {
  // etc.
}

message SerifXML {
  /** Unique identifier. */
  required UUID uuid = 1;

  /** Information about where this serifxml came from. */
  optional AnnotationMetadata metadata = 2;

  /** The xml itself */
  optional bytes xml = 3;

}

//===========================================================================
// Spans in Text/Audio
//===========================================================================

/** A span of text within a single communication, identified by a pair
 * of character offsets.  In this context, a "character offset" is a
 * zero-based count of UTF-16 codepoints.  I.e., if you are using
 * Java, or are using a Python build where sys.maxunicode==0xffff,
 * then the "character offset" is an offset into the standard
 * (unicode) string data type.  If you are using a Python build where
 * sys.maxunicode==0xffffffff, then you would need to encode the
 * unicode string using UTF-16 before using the character offsets. */
message TextSpan {
  /** Start character, inclusive. */
  optional uint32 start = 1;
  /** End character, exclusive */
  optional uint32 end = 2;
}

/** A span of audio within a single communication, identified by a
 * pair of time offests.  In this context, a "time offset" is a float
 * containing the number of seconds since the beginning of the
 * message.  Time offsets are zero-based.*/
message AudioSpan {
  /** Start time (in seconds)*/
  optional float start = 1;
  /** End time (in seconds)*/
  optional float end = 2;

  // NOTE: we reserve the right to add a "channel" field or something
  // analogous, for multi-channel audio (left/right, etc).
}

//===========================================================================
// Sections (aka "Regions" or "Zones")
//===========================================================================

/** A theory about how a communication is broken down into smaller
 * sections (such as paragraphs).  The sections should be ordered
 * and non-overlapping. */
message SectionSegmentation {
  /** Unique identifier for this segmentation. */
  required UUID uuid = 1;
  
  /** Information about where this segmentation came from. */
  optional AnnotationMetadata metadata = 2;

  /** Ordered list of sections in this segmentation. */
  repeated Section section = 3;
}

/** A single "section" of a communication, such as a paragraph.  Each
 * section is defined using a text or audio span, and can optionally
 * contain a list of sentences. */
message Section {
  required UUID uuid = 1;

  /** Location of this section in the original text. */
  optional TextSpan text_span = 2;

  /** Location of this section in the original audio. */
  optional AudioSpan audio_span = 3;

  /** Theories about how this section is divided into sentences. */
  repeated SentenceSegmentation sentence_segmentation = 4;

  /** The type of this section. */
  optional Kind kind = 5 [default=OTHER];
  enum Kind {
    OTHER = 0;
    PARAGRAPH = 1;
    TABLE = 2;
    // etc..
  }
}

//===========================================================================
// Sentences
//===========================================================================

/** A theory about how a section of a communication is broken down
 * into sentences (or utterances).  The sentences in a
 * SentenceSegmentation should be ordered and non-overlapping. */
message SentenceSegmentation {
  /** Unique identifier for this segmentation. */
  required UUID uuid = 1;
  
  /** Information about where this segmentation came from. */
  optional AnnotationMetadata metadata = 2;

  /** Ordered list of sentences in this segmentation. */
  repeated Sentence sentence = 3;
}

/** A single sentence or utterance in a communication. */
message Sentence {
  /** Unique identifier for this sentence. */
  required UUID uuid = 1;

  /** Location of this sentence in the original text. */
  optional TextSpan text_span = 2;

  /** Location of this sentence in the original audio. */
  optional AudioSpan audio_span = 3;

  /** Theories about the tokens that make up this sentence.  For text
    * communications, these tokenizations will typically be generated
    * by a tokenizer.  For audio communications, these tokenizations
    * will typically be generated by an automatic speech recognizer. 
    *
    * The "Tokenization" message type is also used to store the output
    * of machine translation systems and text normalization
    * systems. */
  repeated Tokenization tokenization = 5;

  /** Theories about the parse structure of this sentence. */
  repeated Parse parse = 6;
}

//===========================================================================
// Tokens & Tokenizations
//===========================================================================

/** A single token (typically a word) in a communication.  The exact
  * definition of what counts as a token is left up to the tools that
  * generate token sequences.  
  *
  * Usually, each token will include at least a text string.
  */
message Token {
  /** A tokenization-relative identifier for this token.  Together
    * with the UUID for a Tokenization, this can be used to define
    * pointers to specific tokens.  If a Tokenization object contains
    * multiple Token objects with the same id (e.g., in different
    * n-best lists), then all of their other fields *must* be
    * identical as well. */
  optional int32 token_id = 1;

  /** Text contents of this token. */
  optional string text = 2;


  /** Location of this token in the original text.  In cases where
    * this token does not correspond directly with any text span in
    * the original text (such as word insertion during MT), this field
    * may be given a value indicating "approximately" where the token
    * comes from.  A span covering the entire sentence may be used if
    * no more precise value seems appropriate. */
  optional TextSpan text_span = 4;

  /** Location of this token in the original audio. */
  optional AudioSpan audio_span = 5;
}

/** A pointer to a token. */
message TokenRef {
  /** The tokenization-relative identifier for the token that is
    * pointed at. */
  optional int32 token_id = 1;

  /** The UUID of the tokenization that contains the token.  This
    * field should only be left empty if the containing tokenization
    * is obvious from context. */
  optional UUID tokenization = 2;
}

/** A list of pointers to tokens that all belong to the same
  * tokenization.  */
message TokenRefSequence {
  /** The tokenization-relative identifiers for each token that is
    * included in this sequence. */
  repeated int32 token_id = 1;

  /** The UUID of the tokenization that contains the tokens.  This
    * field should only be left empty if the containing tokenization
    * is obvious from context. */
  optional UUID tokenization = 2;
}

/** A theory (or set of alternative theories) about the sequence of
  * tokens that make up a sentence.
  *
  * This message type is used to record the output of not just for
  * tokenizers, but also for a wide variety of other tools, including
  * machine translation systems, text normalizers, part-of-speech
  * taggers, and stemmers.
  * 
  * Each Tokenization is encoded using either a single list of tokens,
  * or a TokenLattice.  (If you want to encode an n-best list, then
  * you should store it as n separate Tokenization objects.)  The
  * "kind" field is used to indicate whether this Tokenization contains
  * a list of tokens or a TokenLattice.
  *
  * The confidence value for each sequence is determined by combining
  * the confidence from the "metadata" field with confidence
  * information from individual token sequences as follows:
  *
  * <ul>
  *   <li> For n-best lists: 
  *        metadata.confidence </li>
  *   <li> For lattices:
  *        metadata.confidence * exp(-sum(arc.weight)) </li>
  * </ul>
  * 
  * Note: in some cases (such as the output of a machine translation
  * tool), the order of the tokens in a token sequence may not
  * correspond with the order of their original text span offsets.
  */
message Tokenization {
  /** Unique identifier for this tokenization. */
  required UUID uuid = 1;

  /** Information about where this tokenization came from. */
  optional AnnotationMetadata metadata = 2;

  /** Enumerated value indicating whether this tokenization is
   * implemented using an n-best list or a lattice. */
  optional Kind kind = 3;
  enum Kind {TOKEN_LIST = 1; TOKEN_LATTICE = 2;}

  /** An ordered list of the tokens in this tokenization.  This field
    * should only have a value if kind==TOKEN_LIST. */
  repeated Token token = 4;

  /** A lattice that compactly describes a set of token sequences that
    * might make up this tokenization.  This field should only have a
    * value if kind==LATTICE. */
  optional TokenLattice lattice = 5;

  /** A lattice structure that assigns scores to a set of token
    * sequences.  The lattice is encoded as an FSA, where states are
    * identified by integers, and each arc is annotated with an
    * optional tokens and a weight.  (Arcs with no tokens are
    * "epsilon" arcs.)  The lattice has a single start state and a
    * single end state.  (You can use epsilon edges to simulate
    * multiple start states or multiple end states, if desired.)
    * 
    * The score of a path through the lattice is the sum of the weights
    * of the arcs that make up that path.  A path with a lower score
    * is considered "better" than a path with a higher score.  
    * 
    * If possible, path scores should be negative log likelihoods
    * (with base e -- e.g. if P=1, then weight=0; and if P=0.5, then
    * weight=0.693).  Furthermore, if possible, the path scores should
    * be globally normalized (i.e., they should encode probabilities).
    * This will allow for them to be combined with other information
    * in a reasonable way when determining confidences for system
    * outputs.
    *
    * TokenLattices should never contain any paths with cycles.  Every
    * arc in the lattice should be included in some path from the start
    * state to the end state.
    */
  message TokenLattice {
    /** Start state for this token lattice. */
    optional int32 start_state = 1   [default=0];
  
    /** End state for this token lattice. */
    optional int32 end_state = 2     [default=0];
  
    /** Type for arcs.  For epsilon edges, leave 'token' blank. */
    message Arc {
      optional int32 src = 1;      //!< state identifier
      optional int32 dst = 2;      //!< state identifier
      optional Token token = 3;    //!< leave empty for epsilon edge
      optional double weight = 4;  //!< additive weight; lower is better
    }
  
    /** The set of arcs that make up this lattice (order is
      * unspecified). */
    repeated Arc arc = 3;

    /** A cached copy of the one-best path through the token lattice.
     * This field must always be kept consistent with the arc-based
     * lattice: if you edit the lattice, then you must either delete
     * this field or ensure that it is up-to-date. */
    optional LatticePath cached_best_path = 4;
    message LatticePath {
      optional float weight = 1;
      repeated Token token = 2;
    }
  }

  /** Theories about various annotations of the tokens
   * in this tokenization. */
  repeated TokenTagging posTags = 6;
  repeated TokenTagging nerTags = 7;
  repeated TokenTagging lemmas = 8;
  repeated TokenTagging langId = 9;
}

/** A theory about some token-level annotation.
 * The TokenTagging consists of a mapping from tokens
 * (using token ids) to string tags (e.g. part-of-speech tags or lemmas).
 *
 * The mapping defined by a TokenTagging may be partial --
 * i.e., some tokens may not be assigned any part of speech tags.
 *
 * For lattice tokenizations, you may need to create multiple
 * part-of-speech taggings (for different paths through the lattice),
 * since the appropriate tag for a given token may depend on the path
 * taken.  For example, you might define a separate
 * TokenTagging for each of the top K paths, which leaves all
 * tokens that are not part of the path unlabeled.
 *
 * Currently, we use strings to encode annotations. In
 * the future, we may add fields for encoding specific tag sets
 * (eg treebank tags), or for adding compound tags.
 */
message TokenTagging {
  /** Unique identifier for this annotation */
  required UUID uuid = 1;

  /** Information about where the annotation came from.
   * This should be used to tell between gold-standard annotations
   * and automatically-generated theories about the data */
  optional AnnotationMetadata metadata = 2;

  /** The mapping from tokens to annotations.
   * This may be a partial mapping. */
  repeated TaggedToken tagged_token = 3;

  message TaggedToken {
    /** A pointer to the token being tagged. */
    optional int32 token_id = 1;

    /** A string containing the annotation.
	 *  If the tag set you are using is not case sensitive,
	 * then all part of speech tags should be normalized to upper case. */
    optional string tag = 2;

    /** Confidence of the annotation. */
    optional float confidence = 3;
  }
}


//===========================================================================
// Parse Trees
//===========================================================================

/** A theory about the syntactic parse of a sentence.
 *
 * \note If we add support for parse forests in the future, then it
 * will most likely be done by adding a new field (e.g.
 * "<tt>forest_root</tt>") that uses a new message type to encode the
 * forest.  A "<tt>kind</tt>" field might also be added (analogous to
 * <tt>Tokenization.kind</tt>) to indicate whether a parse is encoded
 * using a simple tree or a parse forest.
 */
message Parse {
  /** Unique identifier for this parse. */
  required UUID uuid = 1;

  /** Information about where this parse came from. */
  optional AnnotationMetadata metadata = 2;

  /** The root constituent of this parse */
  optional Constituent root = 3;

  /** A single parse constituent (or "phrase"). */
  message Constituent {
    /** A parse-relative identifier for this consistuent.  Together
    * with the UUID for a Parse, this can be used to define
    * pointers to specific constituents. */
    optional int32 id = 5;

    optional string tag = 1;

    /** The list of parse constituents that are directly dominated by
      * this constituent. */
    repeated Constituent children = 2;

    /** The list of pointers to the tokens dominated by this
      * constituent.  Typically, this field will only be defined for
      * leaf constituents (i.e., constituents with no children).  For
      * many parsers, len(tokens) will always be either 1 (for leaf
      * constituents) or 0 (for non-leaf constituents). */
    optional TokenRefSequence token_sequence = 3;

    /** The index of the head child of this constituent.  I.e., the
      * head child of constituent <tt>c</tt> is
      * <tt>c.children[c.head_child_index]</tt>.  A value of -1
      * indicates that no child head was identified. */
    optional sint32 head_child_index = 4 [default=-1];
  }
}

//===========================================================================
// Audio Data
//===========================================================================

/** A sound wave.  A separate optional field is defined for each
  * suppported format.  Typically, a Sound object will only define
  * a single field.
  *
  * Note: we may want to have separate fields for separate channels
  * (left vs right), etc.
  */
message Sound {
  // Todo: decide what sound-file types we want to support.
  optional bytes wav = 1;
  optional bytes mp3 = 2;
  optional bytes sph = 3;

  /** An absolute path to a file on disk where the sound file can be
   * found.  It is assumed that this path will be accessable from any
   * machine that the system is run on (i.e., it should be a shared
   * disk, or possibly a mirrored directory). */
  optional string path = 4;
}

//===========================================================================
// Metadata
//===========================================================================
// [xx] should we merge these into a single "Metadata" type?

/** Metadata associated with an annotation or a set of annotations,
  * that identifies where those annotations came from. */
message AnnotationMetadata {
  /** The name of the tool that generated this annotation. */
  optional string tool = 1;

  /** The time at which this annotation was generated (in unix time
   * UTC -- i.e., seconds since January 1, 1970). */
  optional double timestamp = 2;

  /** Confidence score.  To do: define what this means!!! */
  optional float confidence = 3;
}

/** Metadata associated with an attribute or edge. */
message AttributeMetadata {
  /** The name of the tool that generated this attribute. */
  optional string tool = 1;

  /** The time at which this annotation was generated (in unix time
   * UTC -- i.e., seconds since January 1, 1970). */
  optional double timestamp = 2;

  /** Confidence score.  To do: define what this means!!! */
  optional float confidence = 3;
}

/** Analytic-specific information about an attribute or edge.  Digests
 * are used to combine information from multiple sources to generate a
 * unified value.  The digests generated by an analytic will only ever
 * be used by that same analytic, so analytics can feel free to encode
 * information in whatever way is convenient. */
message Digest {
  /** The following fields define various ways you can store the
   * digest data (for convenience).  If none of these meets your
   * needs, then serialize the digest to a byte sequence and store it
   * in bytes_value. */
  optional bytes bytes_value = 1;
  optional int64 int64_value = 2;
  optional double double_value = 3;
  optional string string_value = 4;
  repeated int64 int64_list = 5;
  repeated double double_list = 6;
  repeated string string_list = 7;
}

//===========================================================================
// Entities
//===========================================================================

/** A single referent (or "entity") that is referred to at least once
 * in a given communication, along with pointers to all of the
 * references to that referent.  The referent's type (e.g., is it a
 * person, or a location, or an organization, etc) is also recorded.
 * 
 * Because each Entity contains pointers to all references to a
 * referent with a given communication, an Entity can be
 * thought of as a coreference set.
 */
message Entity {
  /** Unique identifier for this entity. */
  required UUID uuid = 1;

  /** An list of pointers to all of the mentions of this Entity's
   * referent.  (type=EntityMention) */
  repeated UUID mention = 4;

  /** The basic type of this entity's referent. */
  optional Type entity_type = 3;

  /** An enumerated type used to record referent types (aka "entity
   * types") for Entities and EntityMentions. 
   *
   * In the future, we may add support for encoding entity subtypes as
   * well.  This would most likely be accomplished by adding a second
   * field with a new enumerated type whose values correspond to fully
   * specified sbutypes (eg "PERSON_INDIVIDUAL" vs "PERSON_GROUP").
   */
  enum Type { // Renamed from "TYPE"
    PERSON = 1;
    ORGANIZATION = 2;
    GPE = 3;
    OTHER = 4;
    DATE = 5;
    FACILITY = 6;
    VEHICLE = 7;
    WEAPON = 8;
    LOCATION = 9;
    TIME = 10;
    URL = 11;
    EMAIL = 12;
    MONEY = 13;
    PERCENTAGE = 14; /** XX is this different from PERCENT?? */
    PHONE_NUMBER = 15;
    OCCUPATION = 16;
    CHEMICAL = 17;
    AGE = 18;
    PERCENT = 19;
    PERSON_NN = 20;
    GPE_ITE = 21;
    ORGANIZATION_ITE = 22;
    JOB_TITLE = 23;
    // This list is expected to grow over time.
  }

  /** Confidence score for this individual entity.  You can also set a
   * confidence score for an entire EntitySet using the EntitySet's
   * metadata. */
  optional float confidence = 6;

  /** A string containing a representative, canonical, or "best" name
   * for this entity's referent.  This string may match one of the
   * mentions' text strings, but it is not required to. */
  optional string canonical_name = 5;
}

/** A theory about the set of entities that are present in a
 * message.  See also: Entity.*/
message EntitySet {
  /** Unique identifier for this set. */
  required UUID uuid = 1;

  /** Information about where this set came from. */
  optional AnnotationMetadata metadata = 2;

  /** List of entities in this set. */
  repeated Entity entity = 3;
}

//===========================================================================
// Entity Mentions
//===========================================================================

/** A span of text with a specific referent, such as a person,
 * organization, or time.  Things that can be referred to by a mention
 * are called "entities."
 * 
 * It is left up to individual EntityMention taggers to decide which
 * referent types and phrase types to identify.  For example, some
 * EntityMention taggers may only identify proper nouns, or may only
 * identify EntityMentions that refer to people.
 *
 * Each EntityMention consists of a sequence of tokens.  This sequence
 * is usually annotated with information about the referent type
 * (e.g., is it a person, or a location, or an organization, etc) as
 * well as the phrase type (is it a name, pronoun, common noun, etc.).
 *
 * EntityMentions typically consist of a single noun phrase; however,
 * other phrase types may also be marked as mentions.  For
 * example, in the phrase "French hotel," the adjective "French" might
 * be marked as a mention for France.
 */
message EntityMention {
  /** A unique idenifier for this entity mention.*/
  required UUID uuid = 1;

  /** The set of tokens that constitute this mention. */
  optional TokenRefSequence token_sequence = 6;

  /** The type of referent that is referred to by this mention. */
  optional Entity.Type entity_type = 4;

  /** The phrase type of the tokens that constitute this mention. */
  optional PhraseType phrase_type = 3;
  enum PhraseType {        // Renamed from "TYPE"
    NAME = 1;              //!< aka "proper noun"
    PRONOUN = 2;
    COMMON_NOUN = 3;
    OTHER = 4;
    APPOSITIVE = 5;
    LIST = 6;
  }

  /** A confidence score for this individual mention.  You can also
   * set a confidence score for an entire EntityMentionSet using the
   * EntityMentionSet's metadata. */
  optional float confidence = 11;

  /** The text content of this entity mention.  This field is
   * typically redundant with the 'token_sequence' field, and may not
   * be generated by all analytics. */
  optional string text = 2;

  /** Location of this entity mention in the original text.  This
   *  field is typically redundant with the 'token_sequence' field,
   *  and may not be generated by all analytics. */
  optional TextSpan text_span = 7;

  /** Location of this token in the original audio. This field is
   *  typically redundant with the 'token_sequence' field, and may not
   *  be generated by all analytics. */
  optional AudioSpan audio_span = 8;

  /**
   * A Coref ID for this mention (e.g., "gold", "hypothesis 1")
   * 
   */
  optional UUID coref_id = 12;

  /**
   * The index pointing to the sentence where this mention was found.
   */
  optional int32 sentence_index = 13;
  
  /**
   * The pointer to the head token.
   */
  optional int32 head_index = 14;
}

/** A theory about the set of entity mentions that are present in a
 * message.  See also: EntityMention*/
message EntityMentionSet {
  /** Unique identifier for this set. */
  required UUID uuid = 1;

  /** Information about where this set came from. */
  optional AnnotationMetadata metadata = 2;

  /** List of mentions in this set. */
  repeated EntityMention mention = 3;
}

/** A pointer to an entity mention.  This class is mainly intended for
 * use when pointing to an entity mention from some data structure
 * outside the communication (e.g., from a knowledge graph vertex). */
message EntityMentionRef {

  /** The UUID of the entity mention that is being pointed at. */
  optional UUID entity_mention_id = 1;

  /** The corpus-relative communication identifier for the
   * communication that contains the mention that is being pointed at.
   *
   * \see CommunicationsGUID.communication_id. */
  optional string communication_id = 3;
}


//===========================================================================
// Situations
//===========================================================================
// [!!] WARNING: THE NAME OF THIS CLASS MAY CHANGE [!!]

/** A single situation, along with pointers to situation mentions that
 * provide evidence for the situation.  "Situations" include events,
 * relations, facts, sentiments, and beliefs.  Each situation has a
 * core type (such as EVENT or SENTIMENT), along with an optional
 * subtype based on its core type (e.g., event_type=CONTACT_MEET), and
 * a set of zero or more unordered arguments. */
message Situation {
  /** Unique identifier for this situation. */
  required UUID uuid = 1;

  /** The core type of this situation (eg EVENT or SENTIMENT) */
  optional Type situation_type = 2;

  /** The arguments for this situation.  Each argument consists of a
   * role and a value.  It is possible for an situation to have
   * multiple arguments with the same role.  Arguments are
   * unordered. */
  repeated Argument argument = 3;

  /** An list of pointers to SituationMentions that provide
   * justification for this situation.  These mentions may be either
   * direct mentions of the situation, or indirect evidence. */
  repeated Justification justification = 4;

  /** The event type for situations where situation_type=EVENT */
  optional EventType event_type = 50;

  /** The state type for situations where situation_type=STATE */
  optional StateType state_type = 51;

  /** An "intensity" rating for this situation, typically ranging from
   * 0-1.  In the case of SENTIMENT situations, this is used to record
   * the intensity of the sentiment. */
  optional float intensity = 100;

  /** The polarity of this situation.  In the case of SENTIMENT
   * situations, this is used to record the polarity of the
   * sentiment. */
  optional Polarity polarity = 101;

  /** A confidence score for this individual situation.  You can also
   * set a confidence score for an entire SituationSet using the
   * SituationSet's metadata. */
  optional float confidence = 200;

  /* An enumerated type used to record the core types of situations.
   * These types form a type hierarchy, as follows:
   *
   *   * SITUATION
   *      * FACT
   *         * CAUSAL_FACT
   *      * EVENT
   *      * STATE (includes ACE-style relations)
   *         * PRIVATE_STATE
   *            * SENTIMENT
   */
  enum Type {
    SITUATION = 0;
    FACT = 100;              //!< Subtype of SITUATION
    CAUSAL_FACT = 110;       //!< Subtype of FACT
    EVENT = 200;             //!< Subtype of SITUATION
    STATE = 300;             //!< Subtype of SITUATION
    PRIVATE_STATE = 310;     //!< Subtype of STATE
    SENTIMENT = 311;         //!< Subtype of PRIVATE_STATE
  }

  /** A situation argument, consisting of an argument role and a value.
   * Argument values may be Entities or Situations. */
  message Argument {
    /** The relationship between this argument and the situation that
     * owns it.  The roles that a situation's arguments can take
     * depend on the type of the situation (including subtype
     * information, such as event_type). */
    optional Role role = 1;

    /** A pointer to the value of this argument, if it is explicitly
     * encoded as an Entity or a Situation. */
    optional UUID value = 2;

    /** The type of this argument's value.  This type must match the
     * type of the protobuf object pointed to by 'value,' when it is
     * defined.  */
    optional ValueType value_type = 3;

    /** Enumerated type used to record the type of the argument's
     * value.  The "SENDER_ARG" value type is a subtype of the
     * "ENTITY_ARG" value type, and should be used when the argument's
     * value is the sender (whether the 'value' pointer is defined or
     * not). */
    enum ValueType {
      UNKNOWN_ARG = 0;
      ENTITY_ARG = 100;
      SENDER_ARG = 110;          //!< Subtype of ENTITY
      SITUATION_ARG = 200;
    }

    /** Enumerated type used to record the relationship between an
     * argument and the situation that owns it. */
    enum Role {
      OTHER_ROLE = 1;
      PERSON_ROLE = 2;
      TIME_ROLE = 3;
      PLACE_ROLE = 4;
      AGENT_ROLE = 5;
      VICTIM_ROLE = 6;
      INSTRUMENT_ROLE = 7;
      VEHICLE_ROLE = 8;
      ARTIFACT_ROLE = 9;
      PRICE_ROLE = 10;
      ORIGIN_ROLE = 11;
      DESTINATION_ROLE = 12;
      BUYER_ROLE = 13;
      SELLER_ROLE = 14;
      BENEFICIARY_ROLE = 15;
      GIVER_ROLE = 16;
      RECIPIENT_ROLE = 17;
      MONEY_ROLE = 18;
      ORG_ROLE = 19;
      ATTACKER_ROLE = 20;
      TARGET_ROLE = 21;
      ENTITY_ROLE = 22;
      POSITION_ROLE = 23;
      DEFENDANT_ROLE = 24;
      ADJUDICATOR_ROLE = 25;
      PROSECUTOR_ROLE = 26;
      CRIME_ROLE = 27;
      PLAINTIFF_ROLE = 28;
      SENTENCE_ROLE = 29;
      TIME_WITHIN_ROLE = 30;
      TIME_STARTING_ROLE = 31;
      TIME_ENDING_ROLE = 32;
      TIME_BEFORE_ROLE = 33;
      TIME_AFTER_ROLE = 34;
      TIME_HOLDS_ROLE = 35;
      TIME_AT_BEGINNING_ROLE = 36;
      TIME_AT_END_ROLE = 37;
      RELATION_SOURCE_ROLE = 38;
      RELATION_TARGET_ROLE = 39;
    }
  }

  /** A pointer to a SituationMention that provides supporting
   * evidence for this situation, along with information about
   * the nature of the support. */
  message Justification {
    /** An enumerated value used to describe the way in which the
     * justification's mention provides supporting evidence for the
     * situation. */
    optional Type justification_type = 1;

    /** A pointer to the SituationMention itself. */
    required UUID mention = 2;

    /** An optional list of pointers to tokens that are (especially)
     * relevant to the way in which this mention provides
     * justification for the situation.  It is left up to individual
     * analytics to decide what tokens (if any) they wish to include
     * in this field. */
    repeated TokenRefSequence tokens = 3;

    /** The way in which the justification's mention provides evidence
     * for the situation.*/
    enum Type {
      DIRECT_MENTION = 1;
      IMPLICIT = 2;
      // this list will grow over time
    }
  }

  /** An enumerated type used to record event types for Situations
   * and SituationMentions where situation_type=EVENT. */
  enum EventType {
    OTHER_EVENT = 1;
    //-----------------------------------------------------------------
    // ACE event types:
    //-----------------------------------------------------------------
    BUSINESS_DECLARE_BANKRUPTCY_EVENT = 2;
    BUSINESS_END_ORG_EVENT = 3;
    BUSINESS_MERGE_ORG_EVENT = 4;
    BUSINESS_START_ORG_EVENT = 5;
    CONFLICT_ATTACK_EVENT = 6;
    CONFLICT_DEMONSTRATE_EVENT = 7;
    CONTACT_MEET_EVENT = 8;
    CONTACT_PHONE_WRITE_EVENT = 9;
    JUSTICE_ACQUIT_EVENT = 10;
    JUSTICE_APPEAL_EVENT = 11;
    JUSTICE_ARREST_JAIL_EVENT = 12;
    JUSTICE_CHARGE_INDICT_EVENT = 13;
    JUSTICE_CONVICT_EVENT = 14;
    JUSTICE_EXECUTE_EVENT = 15;
    JUSTICE_EXTRADITE_EVENT = 16;
    JUSTICE_FINE_EVENT = 17;
    JUSTICE_PARDON_EVENT = 18;
    JUSTICE_RELEASE_PAROLE_EVENT = 19;
    JUSTICE_SENTENCE_EVENT = 20;
    JUSTICE_SUE_EVENT = 21;
    JUSTICE_TRIAL_HEARING_EVENT = 22;
    LIFE_BE_BORN_EVENT = 23;
    LIFE_DIE_EVENT = 24;
    LIFE_DIVORCE_EVENT = 25;
    LIFE_INJURE_EVENT = 26;
    LIFE_MARRY_EVENT = 27;
    MOVEMENT_TRANSPORT_EVENT = 28;
    PERSONNEL_ELECT_EVENT = 29;
    PERSONNEL_END_POSITION_EVENT = 30;
    PERSONNEL_NOMINATE_EVENT = 31;
    PERSONNEL_START_POSITION_EVENT = 32;
    QUOTATION_DEFINITE_EVENT = 33;
    QUOTATION_POSSIBLE_EVENT = 34;
    TRANSACTION_TRANSFER_MONEY_EVENT = 35;
    TRANSACTION_TRANSFER_OWNERSHIP_EVENT = 36;
  }

  /** An enumerated type used to record event types for Situations
   * and SituationMentions where situation_type=STATE. */
  enum StateType {
    OTHER_STATE = 1;
    //-----------------------------------------------------------------
    // ACE 2004 relations:
    //-----------------------------------------------------------------
    ART_INVENTOR_OR_MANUFACTURER_STATE = 37;
    ART_OTHER_STATE = 38;
    ART_USER_OR_OWNER_STATE = 39;
    DISC_STATE = 40;
    PHYS_LOCATED_STATE = 41; // Also in ACE 2005
    PHYS_NEAR_STATE = 42; // Also in ACE 2005
    PHYS_PART_WHOLE_STATE = 43;
    EMP_ORG_EMPLOY_EXECUTIVE_STATE = 44;
    EMP_ORG_EMPLOY_STAFF_STATE = 45;
    EMP_ORG_EMPLOY_UNDETERMINED_STATE = 46;
    EMP_ORG_MEMBER_OF_GROUP_STATE = 47;
    EMP_ORG_OTHER_STATE = 48;
    EMP_ORG_PARTNER_STATE = 49;
    EMP_ORG_SUBSIDIARY_STATE = 50;
    GPE_AFF_BASED_IN_STATE = 51;
    GPE_AFF_CITIZEN_OR_RESIDENT_STATE = 52;
    GPE_AFF_OTHER_STATE = 53;
    OTHER_AFF_ETHNIC_STATE = 54;
    OTHER_AFF_IDEOLOGY_STATE = 55;
    OTHER_AFF_OTHER_STATE = 56;
    PER_SOC_BUSINESS_STATE = 57; // Also in ACE 2005
    PER_SOC_FAMILY_STATE = 58; // Also in ACE 2005
    PER_SOC_OTHER_STATE = 59;
    //-----------------------------------------------------------------
    // ACE 2005 relations:
    //-----------------------------------------------------------------
    ART_USER_OWNER_INVENTOR_MANUFACTURER_STATE = 60;
    GEN_AFF_CITIZEN_RESIDENT_RELIGION_ETHNICITY_STATE = 61;
    GEN_AFF_ORG_LOCATION_STATE = 62;
    ORG_AFF_EMPLOYMENT_STATE = 63;
    ORG_AFF_FOUNDER_STATE = 64;
    ORG_AFF_OWNERSHIP_STATE = 65;
    ORG_AFF_STUDENT_ALUM_STATE = 66;
    ORG_AFF_SPORTS_AFFILIATION_STATE = 67;
    ORG_AFF_INVESTOR_SHAREHOLDER_STATE = 68;
    ORG_AFF_MEMBERSHIP_STATE = 69;
    PART_WHOLE_ARTIFACT_STATE = 70;
    PART_WHOLE_GEOGRAPHICAL_STATE = 71;
    PART_WHOLE_SUBSIDIARY_STATE = 72;
    PER_SOC_LASTING_PERSONAL_STATE = 73;
    //-----------------------------------------------------------------
    // This list is expected to grow over time.
  }

  /** An enumeration used to record the polarity of a situation.
   * This is primarily intended for use with SENTIMENT situations. */
  enum Polarity {
    POSITIVE_POLARITY = 1;
    NEGATIVE_POLARITY = 2;
    NEUTRAL_POLARITY = 3;
    BOTH_POLARITY = 4;
  }
}

/** A theory about the set of situations that are present in a 
 * message.  See also: Situation */
message SituationSet {
  /** Unique identifier for this set. */
  required UUID uuid = 1;

  /** Information about where this set came from. */
  optional AnnotationMetadata metadata = 2;

  /** List of mentions in this set. */
  repeated Situation situation = 3;
}

//===========================================================================
// Situation Mentions
//===========================================================================

/** A concrete mention of a situation, where "situations" include
 * events, relations, facts, sentiments, and beliefs.  Each situation
 * has a core type (such as EVENT or SENTIMENT), along with an
 * optional subtype based on its core type (e.g.,
 * event_type=CONTACT_MEET), and a set of zero or more unordered
 * arguments. */
message SituationMention {
  /** Unique identifier for this situation. */
  required UUID uuid = 1;

  /** The core type of this situation (eg EVENT or SENTIMENT) */
  optional Situation.Type situation_type = 3;

  /** The arguments for this situation mention.  Each argument
   * consists of a role and a value.  It is possible for an situation
   * to have multiple arguments with the same role.  Arguments are
   * unordered. */
  repeated Argument argument = 4;

  /** The event type for situations where situation_type=EVENT */
  optional Situation.EventType event_type = 50;

  /** The state type for situations where situation_type=STATE */
  optional Situation.StateType state_type = 51;

  /** An "intensity" rating for the situation, typically ranging from
   * 0-1.  In the case of SENTIMENT situations, this is used to record
   * the intensity of the sentiment. */
  optional float intensity = 100;

  /** The polarity of this situation.  In the case of SENTIMENT
   * situations, this is used to record the polarity of the
   * sentiment. */
  optional Situation.Polarity polarity = 101;

  /** An optional list of pointers to tokens that are (especially)
   * relevant to this situation mention.  It is left up to individual
   * analytics to decide what tokens (if any) they wish to include in
   * this field.  In particular, it is not specified whether the
   * arguments' tokens should be included. */
  repeated TokenRefSequence tokens = 150;

  /** An optional list of text spans that are (especially) relevant to
   * this situation mention.  It is left up to individual analytics to
   * decide what tokens (if any) they wish to include in this
   * field.  Note that this field may be redundant with the 'tokens'
   * field in cases where they are both generated. */
  repeated TextSpan text_span = 151;

  /** An optional list of audio spans that are (especially) relevant to
   * this situation mention.  It is left up to individual analytics to
   * decide what tokens (if any) they wish to include in this
   * field.  Note that this field may be redundant with the 'tokens'
   * field in cases where they are both generated. */
  repeated AudioSpan audio_span = 152;

  /** A confidence score for this individual situation mention.  You
   * can also set a confidence score for an entire SituationMentionSet
   * using the SituationMentionSet's metadata. */
  optional float confidence = 200;

  /** A situation mention argument, consisting of an argument role and
   * a value.  Argument values may be EntityMentions or
   * SituationMentions. */
  message Argument {
    /** The relationship between this argument and the situation
     * mention that owns it. */
    optional Situation.Argument.Role role = 1;

    /** A pointer to the value of this argument, if it is explicitly
     * encoded as an EntityMention or a SituationMention. */
    optional UUID value = 2;

    /** The type of this argument's value.  This type must match the
     * type of the protobuf object pointed to by 'value,' when it is
     * defined.  */
    optional Situation.Argument.ValueType value_type = 3;
  }
}

/** A theory about the set of situation mentions that are present in a
 * message.  See also: SituationMention */
message SituationMentionSet {
  /** Unique identifier for this set. */
  required UUID uuid = 1;

  /** Information about where this set came from. */
  optional AnnotationMetadata metadata = 2;

  /** List of mentions in this set. */
  repeated SituationMention mention = 3;
}

//===========================================================================
// Concepts
//===========================================================================

/** A set of concepts associated with some target, such as a message
 * or vertex. */
message ConceptSet {
  /** Unique identifier for this concept set. */
  required UUID uuid = 1;

  /** Information about where this concept set came from. */
  optional AnnotationMetadata metadata = 2;

  /** The set of concepts contained in this set */
  repeated Concept concept = 3;
}

/** A named concept, with an optional weight */
message Concept {
  optional string name = 1;
  optional float weight = 2;
  optional string short_name = 3;
}

//===========================================================================
// Twitter Metadata
//===========================================================================
/* Twitter Metadata
 *
 * This section defines protobuf entries that can be used to store all
 * of the information that is provided by the Twitter API.  This set
 * of definitions is meant to map one-to-one with the Twitter API data
 * structures; do not add any new fields that do not have
 * corresponding fields in the Twitter API. 
 *
 * https://dev.twitter.com/docs/platform-objects/
 * */

/** Information about a twitter user. */
message TwitterUser {
  optional int64 id = 1;
  optional string name = 3;
  optional string screen_name = 4;
  optional string lang = 5;
  optional bool geo_enabled = 6;
  optional string created_at = 7;
  optional int32 friends_count = 8;
  optional int32 statuses_count = 9;
  optional bool verified = 10;
  optional int32 listed_count = 11;
  optional int32 favourites_count = 12; // note british spelling; derived from Twitter schema
  optional int32 followers_count = 13;
                    
  optional string location = 14; // may be empty
  optional string time_zone = 15; // may be empty
  optional string description = 16; // may be empty
  optional sint32 utc_offset = 18; // may be empty
  optional string url = 19; // may be empty

  //======================================================================
  /** \deprecated -- Use `id` instead. */    
  optional string id_str = 2 [deprecated=true];
}

/** Information about a tweet. */
message TweetInfo {
  optional int64 id = 1;
  optional string text = 3;
  optional string created_at = 4; // may be empty; use Message.start_time instead if you are processing a Message.
  optional TwitterUser user = 5; // may just contain TwitterUser.id and TwitterUser.screen_name.
  optional bool truncated = 6;
  optional TwitterEntities entities = 7;
  optional string source = 8;
    
  optional TwitterCoordinates coordinates = 9; // may be empty
  optional TwitterPlace place = 11; // may be empty

  optional bool favorited = 12;
  optional bool retweeted = 13;
  optional int32 retweet_count = 14; // may be empty; in rare cases, might be a string

  optional string in_reply_to_screen_name = 15; // may be empty
  optional int64 in_reply_to_status_id = 16; // may be empty
  optional int64 in_reply_to_user_id = 18; // may be empty

  //======================================================================
  // Deprecated fields: for details on why these are deprecated, see 
  // https://dev.twitter.com/docs/platform-objects/tweets
  //======================================================================
  /** \deprecated -- Use `coordinates` instead. */
  optional TwitterGeo geo = 10 [deprecated=true];
  /** \deprecated -- Use `id` instead. */    
  optional string id_str = 2 [deprecated=true];
  /** \deprecated -- Use `in_reply_to_status_id` instead. */    
  optional string in_reply_to_status_id_str = 17 [deprecated=true];
  /** \deprecated -- Use `in_reply_to_user_id` instead. */    
  optional string in_reply_to_user_id_str = 19 [deprecated=true];
}

/** A twitter geocoordinate */
message TwitterLatLong {
  optional double latitude = 1;
  optional double longitude = 2;
}

/** A twitter location */
message TwitterPlace {
  optional string place_type = 1;
  optional string country_code = 2;
  optional string country = 3;
  optional string full_name = 4;
  optional string name = 5;
  optional string id = 6;
  optional string url = 7;
    
  message BoundingBox {
    optional string type = 1;
    repeated TwitterLatLong coordinates = 2;
  }
    
  optional BoundingBox bounding_box = 8; // may be empty
    
  message PlaceAttributes {
    optional string street_address = 1; // may be empty
    optional string region = 2; // may be empty
    optional string locality = 3; // may be empty
  }
    
  optional PlaceAttributes attributes = 9; // may be empty
}

/** \deprecated -- Use TwitterCoordinates instead */
message TwitterGeo {
  optional string type = 1;
  optional TwitterLatLong coordinates = 2;
}

message TwitterCoordinates {
  optional string type = 1; 
  optional TwitterLatLong coordinates = 2;
}


message TwitterEntities { 
  message UserMention {
    optional int32 start_offset = 1;
    optional int32 end_offset = 2;
    optional string screen_name = 4;
    optional string name = 5;
    optional int64 id = 6;
    /** \deprecated -- Use `id` instead. */    
    optional string id_str = 3 [deprecated=true];
  }

  message URL {
    optional int32 start_offset = 1;
    optional int32 end_offset = 2;
    optional string expanded_url = 3; // may be empty
    optional string url = 4;
    optional string display_url = 5; // may be empty
  }

  message HashTag {
    optional string text = 1;
    optional int32 start_offset = 2;
    optional int32 end_offset = 3;
  }

  repeated HashTag hashtags = 1;
  repeated URL urls = 2;
  repeated UserMention user_mentions = 3;
}

//===========================================================================
// Knowledge Graph
//===========================================================================

/** A knowledge graph, consisting of a set of vertices, along with
 * edges connecting those vertices.  This message type is only used
 * when storing the knowledge graph for an individual communication;
 * for corpus-wide knowledge graphs, the vertices and edges are stored
 * as top-level objects.
 */
message KnowledgeGraph {
  /** Unique identifier for this knowledge graph. */
  required UUID uuid = 1;

  /** The set of vertices in this knowledge graph. */
  repeated Vertex vertex = 2;

  /** The set of edges in this knowledge graph.  There should be at
   * most one edge between any given pair of vertices. */
  repeated Edge edge = 3;
}

/** A vertex in the knowledge graph. */
message Vertex {
  /** A unique identifier for this vertex. */
  required UUID uuid = 1;

  /** UUIDs of vertices that are connected to this vertex by an edge */
  repeated UUID neighbor = 2;

  /** A theory about what kind of Vertex this is.  This determines
   * which of the attribute fields are appropriate for this vertex.
   * (E.g., it is not appropriate to add a communication_guid
   * attribute to a PERSON vertex.)  Note that it is possible to have
   * multiple theories about the kind of a vertex.  For example, we
   * might not be able to tell whether a given vertex corresponds to a
   * person or an organization. */
  repeated VertexKindAttribute kind = 3;
  enum Kind {
    NONE = 0;
    PERSON = 1;
    COMMUNICATION = 2;
    COM_CHANNEL = 3;
  }

  /** A theory about the name of the person or entity represented by
   * this vertex.  If an entity has by multiple names (e.g.,
   * nicknames), then the vertex should have multiple name attributes
   * associated with it. 
   *
   * @ingroup PERSON_VERTEX
   */
  repeated StringAttribute name = 10;

  /** A theory about this person's gender. 
   *
   * @ingroup PERSON_VERTEX
   */
  repeated BooleanAttribute is_male = 11;

  /** A theory about this person's age. 
   *
   * @ingroup PERSON_VERTEX
   */
  repeated FloatAttribute age = 12;

  /** A theory about this person's nationality.  The value of this
   * attribute should be a string name of a country, preferably
   * normalized. 
   *
   * @ingroup PERSON_VERTEX
   */
  repeated StringAttribute nationality = 13;

  /** A theory about whether this person is married. 
   *
   * @ingroup PERSON_VERTEX
   */
  repeated BooleanAttribute is_married = 14;

  /** A theory about whether this person is a parent (i.e., about
   * whether they have any children). 
   *
   * @ingroup PERSON_VERTEX
   */
  repeated BooleanAttribute is_parent = 15;

  /** A theory about whether this person is a grandparent (i.e.,
   * about whether they have any grandchildren). 
   *
   * @ingroup PERSON_VERTEX
   */
  repeated BooleanAttribute is_grandparent = 16;

  /** A string comment about this vertex. 
   *
   * @ingroup ANY_VERTEX
   */
  repeated StringAttribute comment = 17;

  /** A theory about the distribution of languages that a person uses
   * in their communications.  This attribute records how often a
   * person speaks in each language; it does not necessarily indicate
   * how fluent they are in that language.  (E.g., a person might be
   * fluent in French but only speak it rarely.)  The string keys of
   * this map should contain ISO 639-3 langauge codes, and the values
   * should be nonnegative floats that sum to one. 
   *
   * @ingroup PERSON_VERTEX
   */
  repeated StringFloatMapAttribute communication_language_distribution = 18;

  /** A theory about an interesting set of words that were used this
   * person's communications. 
   *
   * @ingroup PERSON_VERTEX
   */
  repeated StringFloatMapAttribute communication_bag_of_words = 19;

  /** A theory about what concepts have been mentioned or discussed in
   * this person's communications. 
   *
   * @ingroup PERSON_VERTEX
   */
  repeated StringFloatMapAttribute communication_concepts = 20;

  /** A theory about what person names have been mentioned in this
   * person's communications.  Keys should be name strings, and values
   * should be counts. 
   *
   * @ingroup PERSON_VERTEX
   */
  repeated StringFloatMapAttribute person_names_mentioned_in_communications = 21;

  /** A theory about what organization names have been mentioned in
   * this person's communications.  Keys should be name strings, and
   * values should be counts. 
   *
   * @ingroup PERSON_VERTEX
   */
  repeated StringFloatMapAttribute organization_names_mentioned_in_communications = 22;

  /** A theory about what location names have been mentioned in this
   * person's communications.  Keys should be name strings, and values
   * should be counts. 
   *
   * @ingroup PERSON_VERTEX
   */
  repeated StringFloatMapAttribute location_names_mentioned_in_communications = 23;

  /** A theory about an interesting set of words that were used in 
   * articles about this person. 
   *
   * @ingroup PERSON_VERTEX
   */
  repeated StringFloatMapAttribute report_bag_of_words = 24;

  /** A theory about what concepts have been mentioned or discussed in
   * articles about this person. 
   *
   * @ingroup PERSON_VERTEX
   */
  repeated StringFloatMapAttribute report_concepts = 25;

  /** A theory about what person names have been mentioned in articles
   * about this person.  Keys should be name strings, and values
   * should be counts. 
   *
   * @ingroup PERSON_VERTEX
   */
  repeated StringFloatMapAttribute person_names_mentioned_in_reports = 26;

  /** A theory about what organization names have been mentioned in
   * articles about this person.  Keys should be name strings, and
   * values should be counts. 
   *
   * @ingroup PERSON_VERTEX
   */
  repeated StringFloatMapAttribute organization_names_mentioned_in_reports = 27;

  /** A theory about what location names have been mentioned in
   * articles about this person.  Keys should be name strings, and
   * values should be counts. 
   *
   * @ingroup PERSON_VERTEX
   */
  repeated StringFloatMapAttribute location_names_mentioned_in_reports = 28;

  /** A theory that this communication corresponds with the
   * communication that has a given commmunication GUID.  Note that in
   * the case of duplicates, it is possible for one vertex to
   * correspond to multiple GUIDs. 
   *
   * @ingroup COMMUNICATION_VERTEX
   */
  repeated CommunicationGUIDAttribute communication_guid = 101;

  /** A theory that this communication channel uses a given twitter id.
   *
   * @ingroup COM_CHANNEL_VERTEX TWITTER_VERTEX */
  repeated Int64Attribute twitter_id = 201;

  /** A theory that this communication channel uses a given twitter handle.
   *
   * @ingroup COM_CHANNEL_VERTEX TWITTER_VERTEX */
  repeated StringAttribute twitter_handle = 202;

  /** A theory that this communication channel uses a given email address
   *
   * @ingroup COM_CHANNEL_VERTEX EMAIL_VERTEX */
  repeated StringAttribute email_address = 203;

  /** A theory that this communication channel uses a given email 
   * display name.
   *
   * @ingroup COM_CHANNEL_VERTEX EMAIL_VERTEX */
  repeated StringAttribute email_display_name = 204;

  /** A theory that this communication channel uses a given phone
   * number.
   *
   * @ingroup COM_CHANNEL_VERTEX PHONE_VERTEX */
  repeated StringAttribute phone_number = 205;
  
  /**
   * Svitlana's political orientation - possible values:
   * DEMOCRATIC, REPUBLICAN
   * 
   */
  repeated StringAttribute political_orientation = 300;
  
  
}

/** A unordered pair of vertex UUIDs, uniquely identifying an edge in
 * a graph.  */
message EdgeId {
  /** The UUID of the vertex of the edge whose UUID is lesser. */
  required UUID v1 = 1;
  /** The UUID of the vertex of the edge whose UUID is greater. */
  required UUID v2 = 2;
}

/** An ordered pair of vertex UUIDs, identifying an edge and an
 * associated direction (source->destination).  There are two possible
 * DirectedEdgeId values corresponding to any given EdgeId: in the
 * "v1-to-v2" directed edge id, src=v1 and dst=v2; and in the
 * "v2-to-v1" directed edge id, src=v2 and dst=v1. */
message DirectedEdgeId {
  /** The UUID of the source vertex */
  required UUID src = 1;
  /** The UUID of the destination vertex */
  required UUID dst = 2;

  /** An enumerated type that can be used to store edge directions */
  enum Direction {
    V1_TO_V2 = 1;
    V2_TO_V1 = 2;
  }
}

/* An edge between two vertices in the knowledge graph, containing a
 * set of undirected attributes between v1 and v2, a set of directed
 * attributes from v1->v2, and a set of directed attributes from
 * v2->v1.
 *
 * Each graph contains exactly one Edge for each unordered pair of
 * vertices.  When an edge is stored in a database table, the sorted
 * pair of vertex UUIDs (e.v1, e.v2) can be used as the row
 * identifier. */
message Edge {
  /** The unique identifier for this edge */
  required EdgeId edge_id = 1;

  /** The set of undirected attributes between the two vertices */
  optional UndirectedAttributes undirected = 6;

  /** The set of directed attributes from v1->v2 */
  optional DirectedAttributes v1_to_v2 = 7;

  /** The set of directed attributes from v2->v1 */
  optional DirectedAttributes v2_to_v1 = 8;
}

/** The undirected attributes for a single edge. */
message UndirectedAttributes {
  repeated StringFloatMapAttribute communication_language_distribution = 6;
  repeated StringFloatMapAttribute communication_bag_of_words = 7;
  repeated StringFloatMapAttribute person_names_mentioned_in_communications = 8;
  repeated StringFloatMapAttribute organization_names_mentioned_in_communications = 9;
  repeated StringFloatMapAttribute location_names_mentioned_in_communications = 10;
  repeated StringFloatMapAttribute communication_concepts = 11;
  repeated StringFloatMapAttribute lda_topics = 12;
  repeated Int32Attribute text_communication_counts = 13;
  repeated Int32Attribute audio_communication_counts = 14;
}

/** The directed attributes for a single edge in a single direction.
 * Each directed attribute has a source vertex and a target vertex. */
message DirectedAttributes {
  /** What relationship does the source have to the target? 
   *
   * @param source PERSON
   * @param target PERSON 
   */
  repeated InterpersonalRelationshipAttribute interpersonal_relationship = 15;

  /** Did the source vertex send the target vertex?
   *
   * @param source PERSON or COM_CHANNEL
   * @param target COMMUNICATION 
   */
  repeated BooleanAttribute is_sender = 17;

  /** Is the source vertex a recipient of the target vertex?
   *
   * @param source PERSON or COM_CHANNEL
   * @param target COMMUNICATION 
   */
  repeated BooleanAttribute is_recipient = 18;

  /** Is the source vertex mentioned in the target vertex?
   *
   * @param source PERSON or COM_CHANNEL
   * @param target COMMUNICATION 
   */
  repeated MentionAttribute is_mentioned = 19;

  /** Does the source vertex use the target vertex?  Note that
   * multiple people may use the same communication channel.
   *
   * @param source PERSON
   * @param target COM_CHANNEL
   */
  repeated BooleanAttribute uses = 20;

  /** How many communications has the source vertex sent using the
   * target vertex?
   *
   * @param source PERSON
   * @param target COM_CHANNEL
   */
  repeated Int32Attribute num_coms_sent = 21;

  /** How many communications has the source vertex received using the
   * target vertex?
   *
   * @param source PERSON
   * @param target COM_CHANNEL
   */
  repeated Int32Attribute num_coms_received = 22;
}

/** A pointer to a vertex in a knowlede graph.  This data structure is
 * used when pointing from one data collection to another. */
message VertexRef {
  required UUID vertex_uuid = 1;
  /** The GUID of this communication that holds this vertex (if it is 
   * part of a communication-local knowledge graph) */
  optional CommunicationGUID communication_guid = 2;
  /** The name of the graph that holds this vertex (if it is part of a
   * distributed graph) */
  optional string graph_name = 3;
}

message EdgeRef {
  required EdgeId edge_id = 1;
  /** The GUID of this communication that holds this edge (if it is 
   * part of a communication-local knowledge graph) */
  optional CommunicationGUID communication_guid = 2;
  /** The name of the graph that holds this edge (if it is part of a
   * distributed graph) */
  optional string graph_name = 3;
}

//===========================================================================
// Knowledge Graph Attributes
//===========================================================================

message VertexKindAttribute {
  required UUID uuid = 1;
  required AttributeMetadata metadata = 2;
  required Vertex.Kind value = 3;
  optional Digest digest = 4;
}

message MentionAttribute {
  required UUID uuid = 1;
  required AttributeMetadata metadata = 2;
  required EntityMentionRef value = 3;
  optional Digest digest = 4;
}

message BooleanAttribute {
  required UUID uuid = 1;
  required AttributeMetadata metadata = 2;
  required bool value = 3;
  optional Digest digest = 4;
}

message StringAttribute {
  required UUID uuid = 1;
  required AttributeMetadata metadata = 2;
  required string value = 3;
  optional Digest digest = 4;
}

message FloatAttribute {
  required UUID uuid = 1;
  required AttributeMetadata metadata = 2;
  required float value = 3;
  optional Digest digest = 4;
}

message Int32Attribute {
  required UUID uuid = 1;
  required AttributeMetadata metadata = 2;
  required int32 value = 3;
  optional Digest digest = 4;
}

message Int64Attribute {
  required UUID uuid = 1;
  required AttributeMetadata metadata = 2;
  required int64 value = 3;
  optional Digest digest = 4;
}

message CommunicationGUIDAttribute {
  required UUID uuid = 1;
  required AttributeMetadata metadata = 2;
  required CommunicationGUID value = 3;
  optional Digest digest = 4;
}

message StringFloatMapAttribute {
  required UUID uuid = 1;
  required AttributeMetadata metadata = 2;
  repeated Entry value = 3;
  message Entry {
    required string key = 1;
    required double value = 2;
  }
  optional Digest digest = 4;
}

/** A theory about the relationship between two people */
message InterpersonalRelationshipAttribute {
  required UUID uuid = 1;
  /** Information about how this attribute was generated */
  required AttributeMetadata metadata = 2;

  /** The nature of the relationship of between the src vertex and the
   * dst vertex.  For example, if the edge from v1 to v2 is labeled
   * with "IS_CHILD_OF", then v1 is the child of v2. */
  required RelationshipType value = 3;
  enum RelationshipType {
    NONE = 0;
    IS_PARENT_OF = 1;
    IS_CHILD_OF = 2;
    IS_OTHER_FAMILY_OF = 3;
    IS_FRIEND_OF = 4;
    IS_BUSINESS_ACQUAINTANCE_OF = 5;
    IS_ROMANTIC_ACQUAINTANCE_OF = 6;
    IS_OTHER_ACQUAINTANCE_OF = 7;
    // This list is expected to grow over time.
  }

  optional Digest digest = 4;
}

